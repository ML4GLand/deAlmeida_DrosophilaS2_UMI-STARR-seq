{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import seqdata as sd\n",
    "import seqpro as sp\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set wd\n",
    "os.chdir(\"/cellar/users/aklie/data/datasets/deAlmeida_DrosophilaS2_UMI-STARR-seq\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "# Load SeqData\n",
    "sdata = sd.open_zarr(\"training/2023_12_20/bp_res/deepstarr_training_bpres_processed.zarr\")\n",
    "sdata.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(203080)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many b'N' characters exist in \"cleaned_seq\"\n",
    "(sdata[\"cleaned_seq\"] == b\"N\").sum().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17461, 5535, 1469, 3300)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdata[\"dev_signal\"][0].values.sum(), sdata[\"hk_signal\"][0].values.sum(), sdata[\"dev_input\"][0].values.sum(), sdata[\"hk_input\"][0].values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata_train = sdata.sel(_sequence=(sdata[\"train_val\"]==True).compute())\n",
    "sdata_valid = sdata.sel(_sequence=(sdata[\"train_val\"]==False).compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training transformations\n",
    "from eugene.dataload._augment import RandomRC\n",
    "\n",
    "def seq_trans(x):\n",
    "    x = np.char.upper(x)\n",
    "    x = sp.ohe(x, sp.alphabets.DNA)\n",
    "    x = x.swapaxes(1, 2)\n",
    "    return x\n",
    "\n",
    "def cov_dtype(x):\n",
    "    return tuple(np.expand_dims(arr, axis=1).astype('f4') for arr in x)\n",
    "\n",
    "def jitter(x):\n",
    "    return sp.jitter(*x, max_jitter=128, length_axis=-1, jitter_axes=0)\n",
    "\n",
    "def to_tensor(x):\n",
    "    return tuple(torch.tensor(arr, dtype=torch.float32) for arr in x)\n",
    "\n",
    "#def random_rc(x):\n",
    "#    return RandomRC(rc_prob=0.5)(*x)\n",
    "\n",
    "# Get the train dataloader\n",
    "dl = sd.get_torch_dataloader(\n",
    "    sdata_train,\n",
    "    sample_dims=['_sequence'],\n",
    "    variables=['cleaned_seq', 'hk_input', 'hk_signal'],\n",
    "    prefetch_factor=None,\n",
    "    batch_size=32,\n",
    "    transforms={\n",
    "        ('cleaned_seq', 'hk_input', 'hk_signal'): jitter,\n",
    "        'cleaned_seq': seq_trans,\n",
    "        'hk_signal': lambda x: x[..., 557:-557],\n",
    "        ('hk_input', 'hk_signal'): cov_dtype,\n",
    "        ('hk_input', 'cleaned_seq', 'hk_signal'): to_tensor,\n",
    "        #('hk_signal', 'hk_input', 'cleaned_seq'): random_rc\n",
    "    },\n",
    "    return_tuples=True,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([32, 4, 2114]),\n",
       " torch.Size([32, 1, 2114]),\n",
       " torch.Size([32, 1, 1000])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test a batch\n",
    "batch = next(iter(dl))\n",
    "[x.shape for x in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40570, 4, 2114]),\n",
       " torch.Size([40570, 1, 2114]),\n",
       " torch.Size([40570, 1, 1000]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the validation data\n",
    "def seq_trans(x):\n",
    "    x = x[..., 128:-128]\n",
    "    np.char.upper(x)\n",
    "    x = sp.ohe(x, sp.alphabets.DNA)\n",
    "    x = x.swapaxes(1, 2)\n",
    "    return torch.as_tensor(x.astype('f4'))\n",
    "\n",
    "def ctl_trans(x):\n",
    "    x = x[..., 128:-128]\n",
    "    return torch.as_tensor(np.expand_dims(x, axis=1).astype('f4'))\n",
    "\n",
    "def cov_trans(x):\n",
    "    x = x[..., 128+557:-128-557]\n",
    "    return torch.as_tensor(np.expand_dims(x, axis=1).astype('f4'))\n",
    "\n",
    "X_valid = seq_trans(sdata_valid[\"cleaned_seq\"].values)\n",
    "X_ctl_valid = ctl_trans(sdata_valid[\"hk_input\"].values)\n",
    "y_valid = cov_trans(sdata_valid[\"hk_signal\"].values)\n",
    "X_valid.shape, X_ctl_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bpnetlite import BPNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BPNet(\n",
       "  (iconv): Conv1d(4, 64, kernel_size=(21,), stride=(1,), padding=(10,))\n",
       "  (irelu): ReLU()\n",
       "  (rconvs): ModuleList(\n",
       "    (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "    (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "    (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "    (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "    (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "    (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "    (6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "    (7): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(256,), dilation=(256,))\n",
       "  )\n",
       "  (rrelus): ModuleList(\n",
       "    (0-7): 8 x ReLU()\n",
       "  )\n",
       "  (fconv): Conv1d(65, 1, kernel_size=(75,), stride=(1,), padding=(37,))\n",
       "  (linear): Linear(in_features=65, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model, we need 1 channel for the signal tracks, and to trim to 1000 bp of input\n",
    "model = BPNet(n_outputs=1, n_control_tracks=1, trimming=(2114 - 1000) // 2, name=\"test.bpnet.seqdata\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 4, 2114]),\n",
       " torch.Size([32, 1, 2114]),\n",
       " torch.Size([32, 1, 1000]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test out a prediction batch\n",
    "batch = next(iter(dl))\n",
    "X, X_ctl, y = batch\n",
    "X.shape, X_ctl.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 1000]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_profile, y_counts = model.forward(X, X_ctl)\n",
    "y_profile.shape, y_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_profile = y_profile.reshape(y_profile.shape[0], -1)\n",
    "y_profile = torch.nn.functional.log_softmax(y_profile, dim=-1)\n",
    "y = y.reshape(y.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the profile and count losses\n",
    "from bpnetlite.losses import MNLLLoss, log1pMSELoss\n",
    "profile_loss = MNLLLoss(y_profile, y).mean()\n",
    "count_loss = log1pMSELoss(y_counts, y.sum(dim=-1).reshape(-1, 1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3160.8975, grad_fn=<MeanBackward0>),\n",
       " tensor(43.6154, grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_loss, count_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BPNet(\n",
       "  (iconv): Conv1d(4, 64, kernel_size=(21,), stride=(1,), padding=(10,))\n",
       "  (irelu): ReLU()\n",
       "  (rconvs): ModuleList(\n",
       "    (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "    (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "    (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "    (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "    (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "    (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "    (6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "    (7): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(256,), dilation=(256,))\n",
       "  )\n",
       "  (rrelus): ModuleList(\n",
       "    (0-7): 8 x ReLU()\n",
       "  )\n",
       "  (fconv): Conv1d(65, 1, kernel_size=(75,), stride=(1,), padding=(37,))\n",
       "  (linear): Linear(in_features=65, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Send the model to the GPU\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quickly define your optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch\tIteration\tTraining Time\tValidation Time\tTraining MNLL\tTraining Count MSE\tValidation MNLL\tValidation Profile Pearson\tValidation Count Pearson\tValidation Count MSE\tSaved?\n",
      "0\t0\t3.4571\t7.9835\t2816.4172\t44.5365\t3869.6133\t0.06639323\t0.37229145\t38.1434\tTrue\n",
      "0\t100\t12.2705\t6.9255\t1909.5676\t2.5685\t3333.1897\t0.16152142\t0.3803567\t3.371\tTrue\n",
      "0\t200\t11.3792\t6.9389\t2682.4829\t3.6374\t2914.5569\t0.24122709\t0.406646\t2.8059\tTrue\n",
      "0\t300\t10.9439\t6.9538\t2459.9956\t3.1004\t2841.1924\t0.26697826\t0.43771183\t2.8311\tTrue\n",
      "0\t400\t12.0476\t6.9665\t2718.2988\t3.0288\t2742.7915\t0.23302194\t0.40544364\t3.1068\tTrue\n",
      "0\t500\t11.5844\t6.9703\t1149.9036\t2.7677\t2721.3228\t0.26276597\t0.39829412\t4.2158\tTrue\n",
      "0\t600\t11.1144\t7.028\t2633.1011\t4.1051\t2528.2271\t0.2732668\t0.44062012\t2.61\tTrue\n",
      "0\t700\t11.7196\t6.9806\t1410.5408\t2.8166\t2588.2927\t0.29798362\t0.4345279\t2.8816\tFalse\n",
      "0\t800\t11.7622\t6.9777\t2581.9556\t1.6955\t2818.5645\t0.21183512\t0.4345917\t2.7239\tFalse\n",
      "0\t900\t11.8255\t6.9773\t3127.3149\t2.7681\t2767.9744\t0.29188547\t0.43575004\t2.7797\tFalse\n",
      "0\t1000\t11.0371\t6.9769\t2014.0092\t3.6376\t2547.5879\t0.30089563\t0.44773895\t2.7256\tFalse\n",
      "0\t1100\t11.2143\t6.9801\t1847.3667\t2.5029\t2471.0491\t0.30482644\t0.4407097\t2.627\tTrue\n",
      "0\t1200\t10.7768\t6.9725\t2959.7812\t4.2459\t2418.6497\t0.29902256\t0.44693613\t2.5593\tTrue\n",
      "0\t1300\t10.6427\t6.9934\t3142.7886\t3.9789\t3083.282\t0.1991276\t0.43893293\t2.5149\tFalse\n",
      "0\t1400\t10.7398\t6.985\t1733.3937\t1.0843\t2475.8459\t0.2560423\t0.45888206\t2.9322\tFalse\n",
      "0\t1500\t10.886\t6.9856\t1760.5695\t2.342\t2381.1821\t0.29229116\t0.4587097\t2.6907\tTrue\n",
      "0\t1600\t11.9421\t6.9841\t2143.8777\t2.8985\t2315.4006\t0.30140987\t0.4518795\t2.5531\tTrue\n",
      "0\t1700\t11.7213\t6.9766\t3039.6475\t1.5025\t2254.5918\t0.29163945\t0.4528509\t2.5581\tTrue\n",
      "0\t1800\t12.4165\t6.9903\t2603.2742\t3.1212\t2264.1128\t0.29477045\t0.44675452\t2.5618\tFalse\n",
      "0\t1900\t12.3104\t6.9878\t1790.2728\t1.3678\t2181.7551\t0.28919324\t0.45696896\t2.5024\tTrue\n",
      "0\t2000\t11.6026\t6.9862\t1468.246\t5.1451\t2154.8899\t0.30768073\t0.4455992\t2.5424\tTrue\n",
      "0\t2100\t10.9703\t6.9847\t1492.814\t3.6444\t2124.9475\t0.31584266\t0.46438748\t2.5067\tTrue\n",
      "0\t2200\t11.5885\t6.976\t3689.8909\t2.162\t2111.4695\t0.318974\t0.4690733\t2.4867\tTrue\n",
      "0\t2300\t11.4643\t6.9853\t1905.9048\t5.4726\t2140.3296\t0.30975878\t0.45591173\t2.5077\tFalse\n",
      "0\t2400\t10.7264\t6.9778\t2529.1318\t3.5014\t2074.3169\t0.31812736\t0.4569498\t2.5861\tTrue\n",
      "0\t2500\t10.7692\t6.9757\t2029.9738\t3.0758\t2012.6008\t0.31906727\t0.46404368\t2.4825\tTrue\n",
      "0\t2600\t10.7714\t6.9763\t1981.3169\t2.8449\t2044.2736\t0.32276466\t0.44999006\t2.5189\tFalse\n",
      "0\t2700\t10.7995\t6.9857\t1462.6969\t4.7877\t1984.3556\t0.32345772\t0.46587476\t2.4814\tTrue\n",
      "0\t2800\t12.4305\t6.9778\t1139.4811\t2.3446\t1990.467\t0.33053666\t0.45767722\t2.4879\tFalse\n",
      "0\t2900\t13.8391\t6.9866\t2181.7256\t1.4428\t1979.0403\t0.33501506\t0.4580034\t2.5024\tTrue\n",
      "0\t3000\t14.121\t6.9819\t1510.3462\t2.319\t1957.4515\t0.33438432\t0.4509403\t2.6162\tTrue\n",
      "0\t3100\t13.209\t7.0062\t2148.5615\t2.0962\t1941.5099\t0.3389852\t0.46624628\t2.4636\tTrue\n",
      "0\t3200\t13.5976\t6.9866\t3194.8843\t2.3081\t2340.9143\t0.3322426\t0.4809133\t2.4677\tFalse\n",
      "0\t3300\t13.8226\t6.9938\t1733.5872\t2.0353\t2069.0339\t0.35644695\t0.4634861\t2.463\tFalse\n",
      "0\t3400\t14.2027\t6.9799\t1730.7383\t1.5006\t2019.6265\t0.36372042\t0.46448755\t2.4529\tFalse\n",
      "0\t3500\t13.5166\t6.9868\t1774.4664\t4.6784\t2034.526\t0.34614506\t0.45408937\t2.467\tFalse\n",
      "0\t3600\t14.1534\t6.9892\t1171.8535\t1.6425\t1993.2321\t0.35675302\t0.42172012\t2.5339\tFalse\n",
      "0\t3700\t14.0091\t6.9907\t3593.8994\t1.9718\t3467.9773\t0.23987131\t0.39663264\t2.5972\tFalse\n",
      "0\t3800\t13.3823\t6.9852\t1632.4434\t2.0564\t2590.5024\t0.30694973\t0.39159605\t2.6895\tFalse\n",
      "0\t3900\t13.5314\t6.9841\t2327.7932\t3.4171\t2439.7534\t0.31968197\t0.39768985\t2.553\tFalse\n",
      "0\t4000\t12.2707\t6.9881\t1994.4253\t2.0369\t2297.4939\t0.32456803\t0.4093816\t2.5104\tFalse\n",
      "0\t4100\t12.496\t6.982\t2148.3613\t1.7574\t2249.0696\t0.33065674\t0.41173965\t2.522\tFalse\n",
      "0\t4200\t12.6873\t6.9734\t1451.0063\t1.6609\t2155.3152\t0.33474052\t0.4069961\t2.53\tFalse\n",
      "0\t4300\t11.9391\t6.9828\t1582.2048\t2.3478\t2214.5435\t0.32648858\t0.41098174\t2.5386\tFalse\n",
      "0\t4400\t13.3962\t6.9821\t1582.1902\t2.0376\t2011.2659\t0.3473409\t0.4135309\t2.5221\tFalse\n",
      "0\t4500\t13.4232\t6.9944\t1810.6478\t2.5632\t2106.9414\t0.33695042\t0.41576618\t2.4842\tFalse\n",
      "0\t4600\t13.1057\t6.9811\t1319.3071\t1.0013\t1964.5322\t0.34620255\t0.41966608\t2.5007\tFalse\n",
      "0\t4700\t13.3608\t6.9847\t2824.4409\t3.2648\t1947.8253\t0.33119646\t0.4136285\t2.4879\tFalse\n",
      "0\t4800\t12.9309\t6.9806\t1642.6904\t2.8279\t2322.4185\t0.25878617\t0.37742817\t2.5542\tFalse\n",
      "0\t4900\t11.2095\t6.9829\t2153.5732\t2.2724\t2139.0447\t0.29029873\t0.40987393\t2.4771\tFalse\n",
      "0\t5000\t10.7549\t6.9729\t2289.1604\t2.8563\t1947.6251\t0.32339832\t0.4131953\t2.4845\tFalse\n",
      "0\t5100\t10.784\t6.974\t1350.6736\t3.0611\t1945.2762\t0.3124583\t0.4181556\t2.4681\tFalse\n",
      "0\t5200\t10.7735\t6.9818\t1536.0034\t2.5627\t1976.1615\t0.33072966\t0.36963177\t2.54\tFalse\n",
      "0\t5300\t10.7278\t6.9776\t1945.6793\t1.4286\t1875.1403\t0.34474\t0.38732317\t2.4928\tTrue\n",
      "0\t5400\t10.8563\t6.9733\t1298.2496\t4.1929\t1902.9326\t0.33610824\t0.39010623\t2.5102\tFalse\n",
      "0\t5500\t11.2489\t6.9807\t1429.6494\t4.2101\t1875.5302\t0.33872843\t0.38807046\t2.5003\tFalse\n",
      "0\t5600\t10.6875\t6.9733\t5274.8271\t2.0948\t2190.6389\t0.24144931\t0.4084375\t2.4766\tFalse\n",
      "0\t5700\t10.7616\t6.9726\t1347.3083\t1.9468\t1904.5803\t0.32265443\t0.41262275\t2.4561\tFalse\n",
      "0\t5800\t10.6777\t6.9822\t1728.684\t1.3193\t1817.0173\t0.35293472\t0.423508\t2.4382\tTrue\n",
      "0\t5900\t10.9446\t6.9754\t1293.6727\t3.04\t1840.8014\t0.3544752\t0.41985902\t2.4741\tFalse\n",
      "0\t6000\t11.3533\t6.9757\t1124.4568\t1.6695\t2145.0581\t0.27832276\t0.40753087\t2.468\tFalse\n",
      "0\t6100\t12.3013\t6.9782\t2637.9199\t2.847\t2331.4236\t0.32800865\t0.36247447\t2.6145\tFalse\n",
      "0\t6200\t12.5986\t6.9811\t1628.7054\t2.3112\t2199.002\t0.34366736\t0.37059212\t2.5332\tFalse\n",
      "0\t6300\t11.2649\t6.9738\t1592.2249\t1.5472\t2186.1963\t0.3432696\t0.37630564\t2.5429\tFalse\n",
      "0\t6400\t11.0225\t6.9733\t1628.4434\t1.5365\t2073.374\t0.36218968\t0.3815439\t2.4918\tFalse\n",
      "0\t6500\t11.4022\t6.9739\t1297.9993\t2.9198\t1980.4226\t0.3666097\t0.38740563\t2.4872\tFalse\n",
      "0\t6600\t11.5431\t6.9722\t1467.9026\t3.6268\t1978.1687\t0.35686043\t0.4073913\t2.4553\tFalse\n",
      "0\t6700\t11.2198\t6.9743\t2190.9146\t3.2157\t1839.5052\t0.36104923\t0.4053478\t2.4576\tFalse\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Use the models fit_generator method to train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m res \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      3\u001b[0m     dl,\n\u001b[1;32m      4\u001b[0m     optimizer,\n\u001b[1;32m      5\u001b[0m     X_valid\u001b[39m=\u001b[39;49mX_valid,\n\u001b[1;32m      6\u001b[0m \tX_ctl_valid\u001b[39m=\u001b[39;49mX_ctl_valid,\n\u001b[1;32m      7\u001b[0m     y_valid\u001b[39m=\u001b[39;49my_valid,\n\u001b[1;32m      8\u001b[0m     max_epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m\n\u001b[1;32m      9\u001b[0m )\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml4gland/lib/python3.9/site-packages/bpnetlite/bpnet.py:341\u001b[0m, in \u001b[0;36mBPNet.fit\u001b[0;34m(self, training_data, optimizer, X_valid, X_ctl_valid, y_valid, max_epochs, batch_size, validation_iter, early_stopping, verbose)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_epochs):\n\u001b[1;32m    339\u001b[0m \ttic \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 341\u001b[0m \t\u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m training_data:\n\u001b[1;32m    342\u001b[0m \t\t\u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m    343\u001b[0m \t\t\tX, X_ctl, y \u001b[39m=\u001b[39m data\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml4gland/lib/python3.9/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml4gland/lib/python3.9/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml4gland/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/projects/ML4GLand/SeqData/seqdata/torch.py:243\u001b[0m, in \u001b[0;36mget_torch_dataloader.<locals>.collate_fn\u001b[0;34m(indices)\u001b[0m\n\u001b[1;32m    241\u001b[0m out: Union[Tuple[torch\u001b[39m.\u001b[39mTensor], Dict[\u001b[39mstr\u001b[39m, NDArray], Dict[\u001b[39mstr\u001b[39m, torch\u001b[39m.\u001b[39mTensor]]\n\u001b[1;32m    242\u001b[0m \u001b[39mwith\u001b[39;00m dask\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mset({\u001b[39m\"\u001b[39m\u001b[39marray.slicing.split_large_chunks\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mFalse\u001b[39;00m}):\n\u001b[0;32m--> 243\u001b[0m     out \u001b[39m=\u001b[39m {\n\u001b[1;32m    244\u001b[0m         k: arr\u001b[39m.\u001b[39misel(selector, missing_dims\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mto_numpy()\n\u001b[1;32m    245\u001b[0m         \u001b[39mfor\u001b[39;00m k, arr \u001b[39min\u001b[39;00m sdata[variables]\u001b[39m.\u001b[39mdata_vars\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    246\u001b[0m     }\n\u001b[1;32m    247\u001b[0m     out \u001b[39m=\u001b[39m cast(Dict[\u001b[39mstr\u001b[39m, NDArray], out)\n\u001b[1;32m    249\u001b[0m \u001b[39m# apply transforms\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/ML4GLand/SeqData/seqdata/torch.py:244\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    241\u001b[0m out: Union[Tuple[torch\u001b[39m.\u001b[39mTensor], Dict[\u001b[39mstr\u001b[39m, NDArray], Dict[\u001b[39mstr\u001b[39m, torch\u001b[39m.\u001b[39mTensor]]\n\u001b[1;32m    242\u001b[0m \u001b[39mwith\u001b[39;00m dask\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mset({\u001b[39m\"\u001b[39m\u001b[39marray.slicing.split_large_chunks\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mFalse\u001b[39;00m}):\n\u001b[1;32m    243\u001b[0m     out \u001b[39m=\u001b[39m {\n\u001b[0;32m--> 244\u001b[0m         k: arr\u001b[39m.\u001b[39;49misel(selector, missing_dims\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mignore\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mto_numpy()\n\u001b[1;32m    245\u001b[0m         \u001b[39mfor\u001b[39;00m k, arr \u001b[39min\u001b[39;00m sdata[variables]\u001b[39m.\u001b[39mdata_vars\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    246\u001b[0m     }\n\u001b[1;32m    247\u001b[0m     out \u001b[39m=\u001b[39m cast(Dict[\u001b[39mstr\u001b[39m, NDArray], out)\n\u001b[1;32m    249\u001b[0m \u001b[39m# apply transforms\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml4gland/lib/python3.9/site-packages/xarray/core/dataarray.py:744\u001b[0m, in \u001b[0;36mDataArray.to_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_numpy\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m    734\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    735\u001b[0m \u001b[39m    Coerces wrapped data to numpy and returns a numpy.ndarray.\u001b[39;00m\n\u001b[1;32m    736\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[39m    DataArray.data\u001b[39;00m\n\u001b[1;32m    743\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 744\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvariable\u001b[39m.\u001b[39;49mto_numpy()\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml4gland/lib/python3.9/site-packages/xarray/core/variable.py:1258\u001b[0m, in \u001b[0;36mVariable.to_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(data, \u001b[39m\"\u001b[39m\u001b[39mchunks\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m   1257\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcompute()\n\u001b[0;32m-> 1258\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, array_type(\u001b[39m\"\u001b[39;49m\u001b[39mcupy\u001b[39;49m\u001b[39m\"\u001b[39;49m)):\n\u001b[1;32m   1259\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mget()\n\u001b[1;32m   1260\u001b[0m \u001b[39m# pint has to be imported dynamically as pint imports xarray\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml4gland/lib/python3.9/site-packages/xarray/core/pycompat.py:64\u001b[0m, in \u001b[0;36marray_type\u001b[0;34m(mod)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39marray_type\u001b[39m(mod: ModType) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DuckArrayTypes:\n\u001b[1;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Quick wrapper to get the array class of the module.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m     \u001b[39mreturn\u001b[39;00m DuckArrayModule(mod)\u001b[39m.\u001b[39mtype\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml4gland/lib/python3.9/site-packages/xarray/core/pycompat.py:37\u001b[0m, in \u001b[0;36mDuckArrayModule.__init__\u001b[0;34m(self, mod)\u001b[0m\n\u001b[1;32m     35\u001b[0m duck_array_type: DuckArrayTypes\n\u001b[1;32m     36\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 37\u001b[0m     duck_array_module \u001b[39m=\u001b[39m import_module(mod)\n\u001b[1;32m     38\u001b[0m     duck_array_version \u001b[39m=\u001b[39m Version(duck_array_module\u001b[39m.\u001b[39m__version__)\n\u001b[1;32m     40\u001b[0m     \u001b[39mif\u001b[39;00m mod \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdask\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml4gland/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:982\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:925\u001b[0m, in \u001b[0;36m_find_spec\u001b[0;34m(name, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1423\u001b[0m, in \u001b[0;36mfind_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1395\u001b[0m, in \u001b[0;36m_get_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1522\u001b[0m, in \u001b[0;36mfind_spec\u001b[0;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:142\u001b[0m, in \u001b[0;36m_path_stat\u001b[0;34m(path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Use the models fit_generator method to train the model\n",
    "res = model.fit(\n",
    "    dl,\n",
    "    optimizer,\n",
    "    X_valid=X_valid,\n",
    "\tX_ctl_valid=X_ctl_valid,\n",
    "    y_valid=y_valid,\n",
    "    max_epochs=50\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 ml4gland",
   "language": "python",
   "name": "ml4gland"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
